{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2ZiKA-kXE1hy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "treino_path = 'nba_treino.csv'\n",
        "teste_path = 'nba_teste.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "rTch02bRU0_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readAndStandardizeInput(file):\n",
        "  df = pd.read_csv(file)\n",
        "  # Standardization (mean 0 std 1)\n",
        "  df.loc[:,'GP':'TOV'] = (df.loc[:,'GP':'TOV'] - df.loc[:,'GP':'TOV'].mean()) / df.loc[:,'GP':'TOV'].std()\n",
        "  return df"
      ],
      "metadata": {
        "id": "AcJZVuNnZIFO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readInputFromFileList(files):\n",
        "  dfs = []\n",
        "  for file in files:\n",
        "    df = pd.read_csv(file)\n",
        "    dfs.append(df)\n",
        "  df = pd.concat(dfs)\n",
        "  df = df.reset_index(drop=True)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "u9TacT_gBYew"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _removeOutliers(df, nstds = 3):\n",
        "  mean = df.loc[:,'GP':'TOV'].mean()\n",
        "  std = df.loc[:,'GP':'TOV'].std()\n",
        "  minLimit = mean - nstds*std\n",
        "  maxLimit = mean + nstds*std\n",
        "  maxOutlier = (df.loc[:,'GP':'TOV'] > maxLimit).sum(axis=1)\n",
        "  minOutlier = (df.loc[:,'GP':'TOV'] < minLimit).sum(axis=1)\n",
        "  outliers = maxOutlier + minOutlier\n",
        "  return df[outliers < 1].copy()"
      ],
      "metadata": {
        "id": "xQV7QnEkqkht"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treatData(df, standardize = True, removeOutliers = True, ndesv = 3):\n",
        "  df_copy = df.copy()\n",
        "  if removeOutliers:\n",
        "   df_copy = _removeOutliers(df_copy)\n",
        "\n",
        "  if(standardize):\n",
        "    # Standardization (mean 0 std 1)\n",
        "    df_copy.loc[:,'GP':'TOV'] = (df_copy.loc[:,'GP':'TOV'] - df_copy.loc[:,'GP':'TOV'].mean()) / df_copy.loc[:,'GP':'TOV'].std()\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "nQ6IcpN4qMwp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateOneToManyEuclidianDistances(arr, arrs):\n",
        "  return np.linalg.norm(arrs - arr, axis=1)"
      ],
      "metadata": {
        "id": "j4sXIgaTFEK6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "TLmwYqYLAVo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knnClassifier(train, instance, k):\n",
        "  predicted_instance = instance.loc['GP':'TOV']\n",
        "  distances = calculateOneToManyEuclidianDistances(predicted_instance, train.loc[:,'GP':'TOV'])\n",
        "  sorting = np.argsort(distances)\n",
        "  neighbors = train.loc[:,'TARGET_5Yrs'][sorting]\n",
        "  kneighbors = neighbors[:k]\n",
        "  if(kneighbors.mean() > 0.5):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "e-ftx_ZSKuWS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def knnPredictMany(train, test, k):\n",
        "  predicted = []\n",
        "  for i in range(test.shape[0]):\n",
        "    predicted.append(knnClassifier(train_df, test.loc[i,'GP':'TOV'], k))\n",
        "  predicted = np.array(predicted)\n",
        "  return predicted"
      ],
      "metadata": {
        "id": "Wln90oK6bG0P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "def knnScikitPredictMany(train, test, k):\n",
        "  neigh = KNeighborsClassifier(n_neighbors=k)\n",
        "  neigh.fit(np.array(train.loc[:,'GP':'TOV']), np.array(train.loc[:,'TARGET_5Yrs']))\n",
        "  return neigh.predict(np.array(test.loc[:,'GP':'TOV']))"
      ],
      "metadata": {
        "id": "QI7z-TTKbpBI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(pred, correct):\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "  for i in range(len(pred)):\n",
        "    if(correct[i] == 1):\n",
        "      if(pred[i] == 0):\n",
        "        FN = FN + 1\n",
        "      if(pred[i] == 1):\n",
        "        TP = TP + 1\n",
        "    if(correct[i] == 0):\n",
        "      if(pred[i] == 0):\n",
        "        TN = TN + 1\n",
        "      if(pred[i] == 1):\n",
        "        FP = FP + 1\n",
        "  return (TP,TN,FP,FN)"
      ],
      "metadata": {
        "id": "Wu0FELlRRwaD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printMetricsAndConfusionMatrix(predicted, actual):\n",
        "  (TP,TN,FP,FN) = evaluate(predicted, actual)\n",
        "  data = {'1': [TP, FN],\n",
        "        '0': [FP , TN]}\n",
        "  confusion_matrix = pd.DataFrame(data, index=[1, 0])\n",
        "  confusion_matrix.columns.name = 'Actual'\n",
        "  confusion_matrix.index.name = 'Predicted'\n",
        "  accuracy =  (TP + TN)/(TP + FP + TN + FN)\n",
        "  recall = TP/(TP+TN)\n",
        "  precision = TP/(TP+FP)\n",
        "  f1 = (2*precision*recall)/(precision+recall)\n",
        "  print(confusion_matrix)\n",
        "  print(\"Accuracy -\", accuracy)\n",
        "  print(\"Recall -\", recall)\n",
        "  print(\"Precision -\", precision)\n",
        "  print(\"F1 -\", f1)"
      ],
      "metadata": {
        "id": "f1WHb__NYhu3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"KNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovBOilOFVrzn",
        "outputId": "f3c0d10e-565f-4cf5-81b8-bbaf2e9fb3ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = readAndStandardizeInput(treino_path)\n",
        "test_df = readAndStandardizeInput(teste_path)\n",
        "nTestInstances = test_df.shape[0]"
      ],
      "metadata": {
        "id": "vOPRro3rZphK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = np.array(test_df.loc[:,'TARGET_5Yrs'])"
      ],
      "metadata": {
        "id": "OjcB1_nwc3ps"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kValues = [2, 10, 50, 80]"
      ],
      "metadata": {
        "id": "fvPN0FH4fu9z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Implemententado\")\n",
        "for k in kValues:\n",
        "  print('k -',k)\n",
        "  predicted = knnPredictMany(train_df,test_df,k)\n",
        "  printMetricsAndConfusionMatrix(predicted,actual)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imrj6VIyK-qD",
        "outputId": "ea20ee1e-c3fc-470f-dc50-2d95bf6e38d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implemententado\n",
            "k - 2\n",
            "Actual      1   0\n",
            "Predicted        \n",
            "1          84  27\n",
            "0          84  73\n",
            "Accuracy - 0.585820895522388\n",
            "Recall - 0.535031847133758\n",
            "Precision - 0.7567567567567568\n",
            "F1 - 0.626865671641791\n",
            "\n",
            "k - 10\n",
            "Actual       1   0\n",
            "Predicted         \n",
            "1          125  44\n",
            "0           43  56\n",
            "Accuracy - 0.6753731343283582\n",
            "Recall - 0.6906077348066298\n",
            "Precision - 0.7396449704142012\n",
            "F1 - 0.7142857142857143\n",
            "\n",
            "k - 50\n",
            "Actual       1   0\n",
            "Predicted         \n",
            "1          128  52\n",
            "0           40  48\n",
            "Accuracy - 0.6567164179104478\n",
            "Recall - 0.7272727272727273\n",
            "Precision - 0.7111111111111111\n",
            "F1 - 0.7191011235955056\n",
            "\n",
            "k - 80\n",
            "Actual       1   0\n",
            "Predicted         \n",
            "1          127  49\n",
            "0           41  51\n",
            "Accuracy - 0.664179104477612\n",
            "Recall - 0.7134831460674157\n",
            "Precision - 0.7215909090909091\n",
            "F1 - 0.7175141242937854\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"__________________________________\")\n",
        "print(\"Scikit Learn\")\n",
        "for k in kValues:\n",
        "  print('k -',k)\n",
        "  predicted_scikit = knnScikitPredictMany(train_df,test_df,k)\n",
        "  printMetricsAndConfusionMatrix(predicted_scikit,actual)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnMBttQ3nU_6",
        "outputId": "09d8397d-4a02-4894-d2c2-54458746fe7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________________________\n",
            "Scikit Learn\n",
            "k - 2\n",
            "Actual      1   0\n",
            "Predicted        \n",
            "1          84  27\n",
            "0          84  73\n",
            "Accuracy - 0.585820895522388\n",
            "Recall - 0.535031847133758\n",
            "Precision - 0.7567567567567568\n",
            "F1 - 0.626865671641791\n",
            "\n",
            "k - 10\n",
            "Actual       1   0\n",
            "Predicted         \n",
            "1          125  44\n",
            "0           43  56\n",
            "Accuracy - 0.6753731343283582\n",
            "Recall - 0.6906077348066298\n",
            "Precision - 0.7396449704142012\n",
            "F1 - 0.7142857142857143\n",
            "\n",
            "k - 50\n",
            "Actual       1   0\n",
            "Predicted         \n",
            "1          128  52\n",
            "0           40  48\n",
            "Accuracy - 0.6567164179104478\n",
            "Recall - 0.7272727272727273\n",
            "Precision - 0.7111111111111111\n",
            "F1 - 0.7191011235955056\n",
            "\n",
            "k - 80\n",
            "Actual       1   0\n",
            "Predicted         \n",
            "1          127  49\n",
            "0           41  51\n",
            "Accuracy - 0.664179104477612\n",
            "Recall - 0.7134831460674157\n",
            "Precision - 0.7215909090909091\n",
            "F1 - 0.7175141242937854\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Means\n"
      ],
      "metadata": {
        "id": "9F9PWmWQAZdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"________________________________________________________\")\n",
        "print(\"K-means\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFSQjU3DV9Zd",
        "outputId": "8cfc50ad-01e1-4c5f-a641-35354cfa2d40"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________________________\n",
            "K-means\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def KMeansClassifyCluster(k, nrows, centroids, all_dataset_df_without_predicted):\n",
        "  distances = np.zeros((k, nrows))\n",
        "  for centroid_i, centroid in enumerate(centroids):\n",
        "    distances[centroid_i,:] = calculateOneToManyEuclidianDistances(centroid, all_dataset_df_without_predicted)\n",
        "  classification = np.argmin(distances, axis=0)\n",
        "  return classification"
      ],
      "metadata": {
        "id": "gy5I3hMvyfaO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KMeansCluster(k,all_dataset_df):\n",
        "  all_dataset_df_without_predicted = all_dataset_df.loc[:,'GP':'TOV'].copy()\n",
        "  nrows = all_dataset_df_without_predicted.shape[0]\n",
        "  centroids = rng.choice(all_dataset_df_without_predicted, size=k, replace=False)\n",
        "  classification = None\n",
        "  new_classification = KMeansClassifyCluster(k, nrows, centroids, all_dataset_df_without_predicted)\n",
        "\n",
        "  while not(np.array_equal(classification, new_classification)):\n",
        "    classification = new_classification\n",
        "    for centroid_i in range(k):\n",
        "      indexes = np.where(classification == centroid_i)[0]\n",
        "      centroid = all_dataset_df_without_predicted.iloc[indexes].mean().values\n",
        "      centroids[centroid_i,:] = centroid\n",
        "    new_classification = KMeansClassifyCluster(k, nrows, centroids, all_dataset_df_without_predicted)\n",
        "  return centroids"
      ],
      "metadata": {
        "id": "nK_Lz9IzAdUO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getMetrics(TP, TN, FP, FN):\n",
        "  accuracy =  (TP + TN)/(TP + FP + TN + FN)\n",
        "  recall = TP/(TP+TN)\n",
        "  precision = TP/(TP+FP)\n",
        "  f1 = (2*precision*recall)/(precision+recall)\n",
        "  return (accuracy, recall, precision, f1)"
      ],
      "metadata": {
        "id": "GjLiYix5j3zw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateKMeans(centroids, all_dataset_df, k):\n",
        "  ans = all_dataset_df.loc[:,'TARGET_5Yrs']\n",
        "  associated = np.zeros([k])\n",
        "  total = all_dataset_df.shape[0]\n",
        "\n",
        "  all_dataset_df_without_predicted = all_dataset_df.loc[:,'GP':'TOV'].copy()\n",
        "  nrows = all_dataset_df.shape[0]\n",
        "  classification = KMeansClassifyCluster(k, nrows, centroids, all_dataset_df_without_predicted)\n",
        "\n",
        "  TP, TN, FP, FN = 0, 0, 0, 0\n",
        "  print(\"count - most frequent - precision\")\n",
        "  correct = 0\n",
        "  for centroid_i in range(k):\n",
        "      indexes = np.where(classification == centroid_i)[0]\n",
        "      associated[centroid_i] = np.round(ans.iloc[indexes].mean())\n",
        "      current_total = indexes.shape[0]\n",
        "      current_correct = (ans.iloc[indexes] == associated[centroid_i]).sum()\n",
        "      correct = correct + current_correct\n",
        "      print(indexes.shape[0], '-', associated[centroid_i], '-', current_correct/current_total)\n",
        "      if(associated[centroid_i] == 1):\n",
        "        TP = TP + current_correct\n",
        "        FP = FP + current_total - current_correct\n",
        "      else:\n",
        "        TN = TN + current_correct\n",
        "        FN = FN + current_total - current_correct\n",
        "  print(\"Summary\")\n",
        "\n",
        "  (accuracy, recall, precision, f1) =getMetrics(TP, TN, FP, FN)\n",
        "  print(\"Accuracy -\", accuracy)\n",
        "  print(\"Recall -\", recall)\n",
        "  print(\"Precision -\", precision)\n",
        "  print(\"F1 -\", f1)"
      ],
      "metadata": {
        "id": "zz48iIO3EsN4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Implemententado\")\n",
        "all_dataset_df = readInputFromFileList([treino_path,teste_path])\n",
        "k = 2\n",
        "standardize = False\n",
        "removeOutliers = True\n",
        "ndesv = 3\n",
        "df = treatData(all_dataset_df,standardize = standardize, removeOutliers = removeOutliers, ndesv = ndesv)\n",
        "rng = np.random.default_rng(seed = 150)\n",
        "centroids = KMeansCluster(k, df)\n",
        "df_std = treatData(all_dataset_df,standardize = standardize, removeOutliers = False)\n",
        "print(\"k -\",k)\n",
        "evaluateKMeans(centroids, df_std, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzxJrvhdsm9P",
        "outputId": "fa43e85c-9aac-463a-e70a-17f0d8980472"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implemententado\n",
            "k - 2\n",
            "count - most frequent - precision\n",
            "589 - 0.0 - 0.5704584040747029\n",
            "751 - 1.0 - 0.7696404793608522\n",
            "Summary\n",
            "Accuracy - 0.682089552238806\n",
            "Recall - 0.6323851203501094\n",
            "Precision - 0.7696404793608522\n",
            "F1 - 0.6942942942942943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "VKtaZmEFvLir"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"__________________________________\")\n",
        "print(\"Scikit Learn\")\n",
        "all_dataset_df = readInputFromFileList([treino_path,teste_path])\n",
        "k = 2\n",
        "standardize = False\n",
        "removeOutliers = True\n",
        "ndesv = 3\n",
        "df = treatData(all_dataset_df,standardize = standardize, removeOutliers = removeOutliers, ndesv = ndesv)\n",
        "kmeans = KMeans(n_clusters=k, random_state=0).fit(df.loc[:,'GP':'TOV'])\n",
        "scikit_centroids = kmeans.cluster_centers_\n",
        "df_std = treatData(all_dataset_df,standardize = standardize, removeOutliers = False)\n",
        "print(\"k -\",k)\n",
        "\n",
        "evaluateKMeans(scikit_centroids, df_std, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgoLRm9TvI1V",
        "outputId": "20288352-2893-4b16-add0-e5e829fa92d1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________________________\n",
            "Scikit Learn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k - 2\n",
            "count - most frequent - precision\n",
            "751 - 1.0 - 0.7696404793608522\n",
            "589 - 0.0 - 0.5704584040747029\n",
            "Summary\n",
            "Accuracy - 0.682089552238806\n",
            "Recall - 0.6323851203501094\n",
            "Precision - 0.7696404793608522\n",
            "F1 - 0.6942942942942943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_________________________________________________\")\n",
        "print(\"distancias centroides\")\n",
        "print(np.linalg.norm(centroids[0] - scikit_centroids[1]))\n",
        "print(np.linalg.norm(centroids[1] - scikit_centroids[0]))\n",
        "print(\"_________________________________________________\")"
      ],
      "metadata": {
        "id": "f_vWYLcELCK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049c84e2-99e3-46ba-8274-2c2791fa3bc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_________________________________________________\n",
            "distancias centroides\n",
            "3.04837100093636e-14\n",
            "2.9765949421506847e-14\n",
            "_________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Implemententado\")\n",
        "all_dataset_df = readInputFromFileList([treino_path,teste_path])\n",
        "k = 3\n",
        "standardize = False\n",
        "removeOutliers = True\n",
        "ndesv = 3\n",
        "df = treatData(all_dataset_df,standardize = standardize, removeOutliers = removeOutliers, ndesv = ndesv)\n",
        "rng = np.random.default_rng(seed = 150)\n",
        "centroids = KMeansCluster(k, df)\n",
        "df_std = treatData(all_dataset_df,standardize = standardize, removeOutliers = False)\n",
        "print(\"k -\",k)\n",
        "evaluateKMeans(centroids, df_std, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUTm6xnJvCgc",
        "outputId": "9c199c2e-678d-4177-f74c-297c1659fcfb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Implemententado\n",
            "k - 3\n",
            "count - most frequent - precision\n",
            "510 - 1.0 - 0.7666666666666667\n",
            "364 - 0.0 - 0.6236263736263736\n",
            "466 - 1.0 - 0.6502145922746781\n",
            "Summary\n",
            "Accuracy - 0.6873134328358209\n",
            "Recall - 0.753528773072747\n",
            "Precision - 0.7110655737704918\n",
            "F1 - 0.731681602530311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"__________________________________\")\n",
        "print(\"Scikit Learn\")\n",
        "all_dataset_df = readInputFromFileList([treino_path,teste_path])\n",
        "k = 3\n",
        "standardize = False\n",
        "removeOutliers = True\n",
        "ndesv = 3\n",
        "df = treatData(all_dataset_df,standardize = standardize, removeOutliers = removeOutliers, ndesv = ndesv)\n",
        "kmeans = KMeans(n_clusters=k, random_state=0).fit(df.loc[:,'GP':'TOV'])\n",
        "scikit_centroids = kmeans.cluster_centers_\n",
        "df_std = treatData(all_dataset_df,standardize = standardize, removeOutliers = False)\n",
        "print(\"k -\",k)\n",
        "evaluateKMeans(scikit_centroids, df_std, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0xqQuIvvn0",
        "outputId": "15995b6c-c0b3-43f3-83eb-e747258b3ca3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________________________\n",
            "Scikit Learn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k - 3\n",
            "count - most frequent - precision\n",
            "509 - 1.0 - 0.768172888015717\n",
            "365 - 0.0 - 0.6246575342465753\n",
            "466 - 1.0 - 0.6502145922746781\n",
            "Summary\n",
            "Accuracy - 0.6880597014925374\n",
            "Recall - 0.7527114967462039\n",
            "Precision - 0.7117948717948718\n",
            "F1 - 0.731681602530311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_________________________________________________\")\n",
        "print(\"distancias centroides\")\n",
        "print(np.linalg.norm(centroids[0] - scikit_centroids[0]))\n",
        "print(np.linalg.norm(centroids[1] - scikit_centroids[1]))\n",
        "print(np.linalg.norm(centroids[2] - scikit_centroids[2]))\n",
        "print(\"_________________________________________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHwkTdjIKcwt",
        "outputId": "fb53785d-82bb-40ad-fcb2-a9cb46b0595e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_________________________________________________\n",
            "distancias centroides\n",
            "0.0482444070817285\n",
            "0.055375801841407855\n",
            "2.5453735000760633e-14\n",
            "_________________________________________________\n"
          ]
        }
      ]
    }
  ]
}